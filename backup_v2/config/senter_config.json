{
  "name": "Senter",
  "version": "2.0.0",
  "description": "Universal AI Personal Assistant with expandable Focus system",
  "focuses_dir": "Focuses",
  "outputs_dir": "outputs",

  "infrastructure_models": {
    "multimodal_decoder": {
      "path": "/home/sovthpaw/Models/Qwen2.5-Omni-3B-GGUF/Qwen2.5-Omni-3B-Q4_K_M.gguf",
      "mmproj": "/home/sovthpaw/Models/Qwen2.5-Omni-3B-GGUF/mmproj-Qwen2.5-Omni-3B-Q8_0.gguf",
      "description": "Fixed infrastructure - Omni 3B for multimodal decoding ONLY (not for reasoning)"
    },
    "embedding_model": {
      "path": "/home/sovthpaw/ai-toolbox/Senter/Models/nomic-embed-text.gguf",
      "description": "Fixed infrastructure - Embeddings for intelligent search"
    }
  },

  "recommended_models": {
    "hermes_3b": {
      "name": "Hermes 3 Llama 3.2 3B",
      "url": "https://huggingface.co/nousresearch/Hermes-3-Llama-3.2-3B/resolve/main/Hermes-3-Llama-3.2-3B.Q4_K_M.gguf",
      "description": "Fast, efficient text model",
      "size_gb": 2.1,
      "is_vlm": false
    },
    "qwen_vl_8b": {
      "name": "Qwen VL 8B",
      "url": "https://huggingface.co/Qwen/Qwen2-VL/resolve/main/Qwen2-VL-8B-Q4_K_M.gguf",
      "description": "Vision + text model",
      "size_gb": 5.4,
      "is_vlm": true
    }
  },

  "focus_creation": {
    "embed_filter_threshold": 4,
    "low_confidence_threshold": 0.5,
    "allow_dynamic_creation": true
  },

  "review_process": {
    "focus_review_interval": 60,
    "user_profile_interval": 60,
    "self_heal_interval": 30,
    "merge_confidence_threshold": 0.7
  },

  "learning": {
    "senter_md_enabled": true,
    "wiki_enabled": true,
    "personality_injection": true,
    "goal_detection": true
  },

  "ui": {
    "theme": "matrix_green",
    "show_internal_processes": false
  },

  "tts_model": {
      "path": "/home/sovthpaw/ai-toolbox/Senter/Models/soprano-70M-Q8_0.gguf",
      "description": "Soprano TTS model for streaming text-to-speech - ultra-fast (<15ms latency)"
    },

  "tts": {
    "enabled": true,
    "streaming": true,
    "chunk_size": 10,
    "overlap_ms": 200
  },

  "system": {
    "max_parallel_processes": 2,
    "context_window": 32768
  }
}
